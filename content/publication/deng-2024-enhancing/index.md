---
title: Enhancing Large Vision Language Models with Self-Training on Image Comprehension
authors:
- admin_eq 
- Pan Lu* 
- Fan Yin
- Ziniu Hu
- Sheng Shen
- James Zou
- Kai-Wei Chang
- Wei Wang
author_notes:
  - 'Equal contribution'
  - 'Equal contribution'
date: '2024-05-30'
publishDate: '2024-05-30'
publication_types:
- article-journal
publication: '*Advances in neural information processing systems* ***(NeurIPS)***'

abstract: We introduce STIC (Self-Training on Image Comprehension) that enhances the understanding and reasoning capabilities of LVLMs through self-generated data. Our experiments across seven benchmarks, including ScienceQA, TextVQA, ChartQA, LLaVA-Bench, MMBench, MM-Vet, and MathVista, demonstrate a notable average accuracy gain of 4.0% by self-training.  

# Summary. An optional shortened abstract.
summary: We introduce STIC (Self-Training on Image Comprehension) that enhances the understanding and reasoning capabilities of LVLMs through self-generated data. Our experiments across seven benchmarks, including ScienceQA, TextVQA, ChartQA, LLaVA-Bench, MMBench, MM-Vet, and MathVista, demonstrate a notable average accuracy gain of 4.0% by self-training.   

tags:
- Large Language Models
- Self-training
- Multi-modal learning

links:
url_pdf: 'https://arxiv.org/pdf/2405.19716'
url_code: 'https://github.com/yihedeng9/STIC'
url_dataset: 'https://huggingface.co/collections/STIC-LVLM/stic-data-6658e7f93aa5d4bb34ef140b'
url_project: 'https://stic-lvlm.github.io/'

# Display this page in the Featured widget?
featured: true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: ''
  focal_point: ''
  preview_only: false
---
